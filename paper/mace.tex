\section{Proposed Batched Bayesian Optimization Algorithm}

\subsection{Multi-objective Optimization of Acquisition Functions}\label{sec:MOForumlation}

\textcolor{red}{See how other MOBO paper formulate multi-objective optimization}

Multi-objective optimization~\cite{MO_overview} can be formulated as:
\begin{equation}
    \label{eq:MOFormulation}
    \begin{aligned}
        & \text{minimize} & & f_1(\bm{x}),~\dots~,f_m(\bm{x})
    \end{aligned}
\end{equation}

For multi-objective optimization, there are more than one objecive to optimize, and usually there does not exist a single solution that simultaneously optimize all these objectives. A design $\bm{x}_1$ is said to be \emph{dominate} by $\bm{x}_2$ if $\forall i \in \{1\dots m\},~f_i(\bm{x}_1) \le f_i(\bm{x}_2)$ and $\exists j \in \{1\dots m\}, f_j(\bm{x}_1) < f_j(\bm{x}_2)$. A design is \emph{Pareto-optimal} if it is not dominated by any other point and dominate at least one point. The whole set of the non-dominated points in the design space is called the \emph{Pareto set}, and the set of non-dominated points in the objective space is called the \emph{Pareto front}. It is often unlikely to get the whole Pareto front as there might be infinite points on the front, the goal of multi-objective optimization is to find a set of designs that approximates the true Pareto front.

There exist many mature multi-objective optimization algorithms, like the non-dominated sorting based genetic algorithm (NSGA-II)~\cite{nsgaii}, and the multi-objective evolutionary algorithm based on decomposition (MOEA/D)~\cite{moead}. In this paper, the multi-objective optimization based on differential evolution (DEMO)~\cite{demo} is used to solve multi-objective optimization problems.


% When we have more than one objective to optimize, the problem is formulated as:

\subsection{MACE}

We propose a novel heuristic for the parallelization of Bayesian optimization.
The parallelization is realized via multi-objective ensemble of multiple
acquisition functions. When we have multiple acquisition functions built from
the same GP model, they may not disagree with each other about which point is
most promising. For example, the value of LCB function always decreases as the
$\sigma(\bm{x})$ increases, however, for the PI function, when $\sigma(\bm{x})$
increases, the value of PI would decrease when $\mu(\bm{x}) < \tau$, and
increase when $\mu(\bm{x}) > \tau$.

% TODO: discuss the difference of acquisition functions: LCB: do not avoid repeated sampling, EI: always positive

With multi-objective optimization, the disagreement between different
acquisition function can be used for the parallelization of Bayesian
optimization, as best trade-off between these acquisition functions can be
captured by the Pareto front.

In the proposed MACE algorithm, the LCB, EI, and PI acquisition functions are selected, but other acquisition functions like KG and PES can also be incorporated into the MACE framework. In each iteration, the following MO problem is constructed:
\begin{equation}
    \label{eq:MO_LCB_EI_PI}
    \begin{aligned}
        & \text{minimize} & & \mathrm{LCB}(\bm{x}),~-\mathrm{EI}(\bm{x}),~-\mathrm{PI}(\bm{x}).
    \end{aligned}
\end{equation}
Then the DEMO multi-objective optimization algorithm is applied to solve \eqref{eq:MO_LCB_EI_PI}. Once the Pareto front of LCB, EI and PI is obtained, the candidate evalution points are then randomly sampled from the Pareto front.

% TODO: We illustrate the proposed MACE algorithm using the Branin-Hoo function~\cite{dixon1978global}
% TODO: plot contour of Branin/Ei/LCB/PI, plot the PS and the PF

The proposed MACE algorithm is described in Algorithm~\ref{alg:MACE}.


\begin{algorithm}
\caption{Multi-objective Acquisition Ensemble Algorithm}
\label{alg:MACE}
\begin{algorithmic}[1]
\STATE Initial Sampling
\STATE Construct initial GP model
\FOR{t = 1, 2, \dots}
    \STATE Construct the LCB, EI and PI functions according to \eqref{eq:LCB} and \eqref{eq:PI_EI}
    \STATE Find the Pareto front of LCB, EI, PI function using the DEMO algorithm
    \STATE Randomly sample B points $\bm{x}_1, \dots, \bm{x}_B$ from the Pareto front where B is the batch size
    \STATE Evaluate $\bm{x}_1, \dots, \bm{x}_B$ to get $y_1 = f(\bm{x}_1),~\dots~,y_B = f(\bm{x}_B)$
    \STATE Update the GP model
\ENDFOR
\STATE Return best $f(\bm{x})$ recorded during iterations
\end{algorithmic}
\end{algorithm}
